# Infer
Performing inference with `Aframe` models using NVIDIA's [Triton Inference Server](https://docs.nvidia.com/deeplearning/triton-inference-server/user-guide/docs/index.html)

## Environment

In the root of the `infer` project, run 
```bash
apptainer build $AFRAME_CONTAINER_ROOT/infer.sif apptainer.def
```
to build the `infer` container.


## Scripts
TODO: explain inference deployment
